{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bec211d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages org.apache.spark:spark-streaming-kafka-0-10_2.12:3.4.0,org.apache.spark:spark-sql-kafka-0-10_2.12:3.4.0 pyspark-shell'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1815438f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "import time\n",
    "kafka_topic_name = \"test-topic\"\n",
    "kafka_bootstrap_servers = 'localhost:9092'\n",
    "# kafka_other_topic = \"second-topic\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2878c594",
   "metadata": {},
   "outputs": [],
   "source": [
    "#     # Define a schema for the orders data\n",
    "#     # order_id,order_product_name,order_card_type,order_amount,order_datetime,order_country_name,order_city_name,order_ecommerce_website_name    \n",
    "orders_schema = StructType() \\\n",
    "        .add(\"order_id\", StringType()) \\\n",
    "        .add(\"order_product_name\", StringType()) \\\n",
    "        .add(\"order_card_type\", StringType()) \\\n",
    "        .add(\"order_amount\", StringType()) \\\n",
    "        .add(\"order_datetime\", StringType()) \\\n",
    "        .add(\"order_country_name\", StringType()) \\\n",
    "        .add(\"order_city_name\", StringType()) \\\n",
    "        .add(\"order_ecommerce_website_name\", StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acddbfab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to Data Kafka + Pyspark Project !!!\n",
      "Stream Data Processing Application Started ...\n",
      "2023-04-18 19:08:52\n",
      "Printing Schema of orders_df: \n",
      "root\n",
      " |-- key: binary (nullable = true)\n",
      " |-- value: binary (nullable = true)\n",
      " |-- topic: string (nullable = true)\n",
      " |-- partition: integer (nullable = true)\n",
      " |-- offset: long (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- timestampType: integer (nullable = true)\n",
      "\n",
      "Printing Schema of orders_df4: \n",
      "root\n",
      " |-- order_country_name: string (nullable = true)\n",
      " |-- order_city_name: string (nullable = true)\n",
      " |-- total_order_amount: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    print(\"Welcome to Data Kafka + Pyspark Project !!!\")\n",
    "    print(\"Stream Data Processing Application Started ...\")\n",
    "    print(time.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "\n",
    "    spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .appName(\" First PySpark Structured Streaming with Kafka and Message Format as JSON\") \\\n",
    "        .master(\"local[*]\") \\\n",
    "        .getOrCreate()\n",
    "\n",
    "    spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "    \n",
    "    orders_df = spark \\\n",
    "        .readStream \\\n",
    "        .format(\"kafka\") \\\n",
    "        .option(\"kafka.bootstrap.servers\", kafka_bootstrap_servers) \\\n",
    "        .option(\"subscribe\", kafka_topic_name) \\\n",
    "        .option(\"startingOffsets\", \"earliest\") \\\n",
    "        .load()\n",
    "    \n",
    "    print(\"Printing Schema of orders_df: \")\n",
    "    orders_df.printSchema()\n",
    "    \n",
    "    orders_df_stream = orders_df\\\n",
    "    .writeStream \\\n",
    "    .format(\"console\") \\\n",
    "    .start()\n",
    "   \n",
    "\n",
    "    orders_df1 = orders_df.selectExpr(\"CAST(value AS STRING)\", \"timestamp\")\n",
    "   \n",
    "\n",
    "\n",
    "    orders_df2 = orders_df1\\\n",
    "        .select(from_json(col(\"value\"), orders_schema)\\\n",
    "        .alias(\"orders\"), \"timestamp\")\n",
    "    \n",
    "    orders_df2_stream = orders_df2 \\\n",
    "    .writeStream \\\n",
    "    .format(\"console\") \\\n",
    "    .start()\n",
    "    \n",
    "   \n",
    "    \n",
    "\n",
    "    orders_df3 = orders_df2.select(\"orders.*\", \"timestamp\")\n",
    "    \n",
    "\n",
    "    # Simple aggregate - find total_order_amount by grouping country, city\n",
    "    orders_df4 = orders_df3.groupBy(\"order_country_name\", \"order_city_name\") \\\n",
    "        .agg({'order_amount': 'sum'}) \\\n",
    "        .select(\"order_country_name\", \"order_city_name\", col(\"sum(order_amount)\") \\\n",
    "        .alias(\"total_order_amount\"))\n",
    "    \n",
    "\n",
    "    \n",
    "    print(\"Printing Schema of orders_df4: \")\n",
    "    orders_df4.printSchema()\n",
    "    \n",
    "#     orders_df4 = orders_df4.select(expr(\"order_country_name as key\"), to_json(struct(\"*\")).alias(\"value\"))\n",
    "    \n",
    "    # Write final result into other topic for debugging purpose\n",
    "    orders_df4_stream = orders_df4 \\\n",
    "        .writeStream \\\n",
    "        .outputMode(\"update\") \\\n",
    "        .option(\"truncate\", \"false\")\\\n",
    "        .trigger(processingTime='5 seconds') \\\n",
    "        .format(\"console\") \\\n",
    "        .start()\n",
    "\n",
    "    orders_df4_stream.awaitTermination()\n",
    "\n",
    "    print(\"Stream Data Processing Application Completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13ff216",
   "metadata": {},
   "outputs": [],
   "source": []
  },
